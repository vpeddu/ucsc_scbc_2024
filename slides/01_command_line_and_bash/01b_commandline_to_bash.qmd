---
title: "01b: From Command Line to Bash"
author: "Roman E. Reggiardo"
date: "`r format(Sys.time(), '%d %B, %Y')`"
format: 
  revealjs:
    chalkboard: true
    smooth-scroll: true
editor: visual
---

```{r include=FALSE}
# need a dummy `R` chunk to get `Bash` chunks to work
library(knitr)
opts_chunk$set(tidy.opts=list(width.cutoff=60),tidy=TRUE)
```

## Scenario: Mutations

-   You work for a **molecular** diagnostics laboratory.

-   As their lead **bioinformatician**, you need to process **DNA sequencing** data generated from patients who might have **Lung Cancer**.

-   The laboratory has decided to **identify disease** using a set of **genes** with known Lung Cancer-causing mutations: **KRAS**, **EGFR**, and **TP53**.

-   The lab team is sending data that might need to be processed further before it can be used.

## Scenario: Your First Job

Is to build a **computational approach** that

1.  Builds your panel of potentially mutated genes
2.  Builds the patient manifest

Eventually, we're going to build a tool that Identifies patient DNA with Lung Cancer-causing mutations

## Reflection

The file you worked with in [01a](https://rreggiar.github.io/ucsc_scbc_2022/slides/01_command_line_and_bash/01a_file_explorer_to_cmdline.html#/title-slide), `talking.txt`, is in `FASTA` format.

```{bash, echo=TRUE}
head -4 ../../data/talking.txt
```

While this file has `.txt` as its *extension*, `FASTA` files usually have `.fa` or `.fasta` -- we'll use `.fa`

What are some things we could do with/to `FASTA` files using the `command line`?

## FASTA files contain sequence `data`

-   Your team is going to provide with a couple different types of `data`

-   This data is `reference data`

    -   the sequences and locations we **expect** and **understand** the genes of interest to have

## **Prediction:**

Given your experience with the `FASTA` format, what do you expect the `head` and `tail` commands to print if you run them on a larger `.fa` file?

## What data do we need to identify mutations?

-   Mutations are **changes to the sequence** of a gene, at least compared to what its **supposed** to be (lots to say on 'supposed' sequences...)

-   But in order to find the **right** mutations, we need to know **where** the mutation happens in the gene, and where the gene is in the **genome**

## Looking at data from the Laboratory

In this scenario, the Lab has sent you a `.fa` file that contains a number of gene `headers` and their corresponding `sequence`.

-   `gene_panel_database.fa` has headers with 5 pieces of information

    -   Gene Name, chromosome, start position, stop position, strand

    -   The `,` used here are called `delimeters` , we'll use them to separate data into `tables`

## Building the diagnostic panel: `gene_panel_database.fa`

Your Lab team has uploaded the `gene_panel_database.fa` file to your fileshare

-   Copy `gene_panel_database.fa` to your `BSCC_2024_folder/data` directory (using the command line)

take a few moments to explore its contents, are there any problems with the data that we need to address?

## Job #1: Extract the gene panel

`gene_panel_database.fa` contains genes you do not want to check for mutations.

-   Extract the headers for **KRAS, EGFR, and TP53**

-   print the headers to a file `final_gene_panel.csv`

-   these are the 'columns' of our data

-   `csv` -- 'comma-separated values'

## Job #1 output

```{bash}
rm ../../data/final_gene_panel.fa
for gene in KRAS EGFR TP53; do grep $gene ../../data/gene_panel_database.fa >> ../../data/final_gene_panel.fa; done
cat ../../data/final_gene_panel.fa
```

## 3 genes means we do everything 3x....but not by hand

You're trying to avoid running the same code over and over to extract the information you need from `gene_panel_database.fa`

-   To do this, we can use `for loops` to 'iterate' over our genes

```{bash, echo=T}
for gene in KRAS EGFR TP53;do echo $gene; done
```

## Iteration: For Loops and Variables

The `for loop` command structure is as follows

```{bash, echo=T, eval=F}
for gene in KRAS EGFR TP53;do echo $gene; done
```

-   for `variable name`

    -   in `list of variable values` ;

        -   do `tool/command` \$`variable name` ;

-   done

in `Bash`, placing `$` in front of a word tells the computer its a `variable`

## Variables in For Loops

Variables (`$variable_name`) allow us to apply the **same operation** to **multiple inputs**

-   In this examples, `$gene` is the variable that we use to represent **KRAS**, **EGFR**, and finally **TP53** in the `for loop`

Try:

```{bash}
for ivana in KRAS EGFR TP53; do echo $ivana; done
```

```{bash, echo=T, eval=F}
for gene in KRAS EGFR TP53;do echo gene; done
```

```{bash, echo=T, eval=F}
for genetic_element in KRAS EGFR TP53;do echo $gene; done
```

```{bash, echo=T, eval=F}
for gene in KRAS EGFR TP53; echo $gene; done
```

```{bash, echo=T, eval=F}
for gene in KRAS EGFR TP53;do echo $gene
```

## Variables in For Loops

Output:

```{bash, echo=T, eval=T, error=T}
for gene in KRAS EGFR TP53;do echo gene; done
```

```{bash, echo=T, eval=T, error=T}
for genetic_element in KRAS EGFR TP53;do echo $gene; done
```

```{bash, echo=T, eval=T, error=T}
for gene in KRAS EGFR TP53; echo $gene; done
```

```{bash, echo=T, eval=T, error=T}
for gene in KRAS EGFR TP53;do echo $gene
```

How do we fix each of these?

## Variables in For Loops

Fixed:

```{bash, echo=T, eval=T, error=T}
for gene in KRAS EGFR TP53;do echo $gene; done
```

```{bash, echo=T, eval=T, error=T}
for genetic_element in KRAS EGFR TP53;do echo $genetic_element; done
```

```{bash, echo=T, eval=T, error=T}
for gene in KRAS EGFR TP53;do echo $gene; done
```

```{bash, echo=T, eval=T, error=T}
for gene in KRAS EGFR TP53;do echo $gene; done
```

## Job #1.5: Do it with iteration!

`gene_panel_database.fa` contains genes you do not want to check for mutations.

-   **Iteratively** Extract the headers for **KRAS, EGFR, and TP53**

-   print the headers to a file `final_gene_panel.csv`

-   these are the 'columns' of our data

-   `csv` -- 'comma-separated values'

## Job #1.5 output

accomplished in one `for loop`

```{bash}
cat ../../data/final_gene_panel.fa
```

## A tool to work with columns: `cut`

-   Your `final_gene_panel.csv` should look something like with **rows** on each line and columns separated by `,`:

    ```{bash}
    cat ../../data/final_gene_panel.csv
    ```

-   Which is *fine*, but still has the `>` from the `FASTA` format -- not something we need anymore

    ```{bash, echo=T}
    # cut -d [delimeter] -f [fields/columns] [input_file]
    cut -d'>' -f2 ../../data/final_gene_panel.csv
    ```

## `cut`, explained

`cut` can separate files based on `delimeters` that represent columns. It can also return only columns you want:

```{bash, echo=T}
# cut -d [delimeter] -f [fields/columns] [input_file]
cut -d'>' -f2 ../../data/final_gene_panel.csv
```

-   in this case, we want to cut the file by `>` and keep only the right (second) slice of data: `-f2`

## Practice 05:

1.  Run:

```{bash, echo=T}
cut -d'>' -f1 ../../data/final_gene_panel.csv
```

-   why doesn't this return anything?

2.  replace the `delimeter` with `,`
    1.  what does setting `-f2` return

    2.  `-f1,4,5` ?

## Practice 05 output:

1.  

```{bash}
cut -d'>' -f1 ../../data/final_gene_panel.csv
```

2\.

```{bash}
cut -d',' -f2 ../../data/final_gene_panel.csv
```

3\.

```{bash}
cut -d',' -f1,4,5 ../../data/final_gene_panel.csv
```

## One product, two steps

What we've just seen with `grep` and `cut` has split the one thing we want to do (making a csv) into two steps:

1.  `grep` and print to the csv
2.  `cut` the file to remove the `>` leftover

instead, we can combine these commands with the `pipe` operator: `|`

```{bash, echo=T}
grep 'KRAS' ../../data/gene_panel_database.fa | cut -d'>' -f2
```

## Complex commands: `piping`

Imagine a literal piece of plumbing connecting the `output` of one command to the `input` of another. This is the `|` operator's function

-   `|` takes the output from the left side and uses it as input on the right:

```{bash, echo=T}
# cmd 1 | cmd 2 [input is derived from | ]
echo 'gene,chromosome,start,stop,strand' | cut -d, -f1,3,5
```

```{bash, echo=T}
# cmd 1 | cmd 2 [input derived from | ] | cmd 3 [input derived from | ]
pwd
pwd | cut -d/ -f8 | cut -d_ -f5
```

## Job #1.75: Putting it all together

`gene_panel_database.fa` contains genes you do not want to check for mutations.

-   **Iteratively** Extract the headers for **KRAS, EGFR, and TP53** and trim off the carrot `>`

-   **append** the headers to a file `final_gene_panel.csv` with the first line:

    -   `gene,chromosome,start,stop,strand`

-   these are the 'columns' of our data

-   `csv` -- 'comma-separated values'

## Job #1.75 output:

```{bash}
echo 'gene,chromosome,start,stop,strand' > ../../data/final_gene_panel.csv & for gene in KRAS EGFR TP53; do grep $gene ../../data/gene_panel_database.fa| cut -d'>' -f2 >> ../../data/final_gene_panel.csv; done
cat ../../data/final_gene_panel.csv
```

## Reflection:

We just did a lot, what stands out to you as the most generally useful thing?

What is the most frustrating/slow/annoying aspect of how we're doing things now?

## Prediction:

How can we use `for` , `pipe` and `$variables` to make our Bioinformatics job smoother?

## Summary Job #1

-   `for` loops enable iteration over multiple values represented by a variable

    -   uses `in` , `do` , and `done`

-   `cut` separated files based on `delimeters` (`-d` ) and allows you to select fields/columns (`-f`) to return

-   `|` pipe operator the end-to-end connection of commands by supplying the output from the left side of `|` as input to the right side.

    -   `cmd1 | cmd2 {output from 1} | cmd3 {output from 2}  â€¦`

## Back to work

Your `for loop` works well and you could see your Bioinformatics job getting a lot easier if you could just save this kind of stuff and use it on the other noisy data the Lab sends you....

Before that, let's work with the patient data the Lab has also sent over

## Job #2: Figuring out who the patients are

Each patient comes into the Lab and fills out a card:

```{bash}
echo patient_id,gene,age,sex
echo 1,KRAS,45,M
```

These are each turned into a `file` and uploaded to the database as a `compressed archive`

## Moving directories as files: `tar/gzip`

You might have seen these before: directories collapsed into a single, movable, compressed file:

-   Laboratory patient data:

    -   [link](https://github.com/rreggiar/ucsc_scbc_2022/raw/master/data/patient_database.tar.gz) (right click and copy)

-   We won't go into detail here, safe to use the following command to `unzip` the archive into the original multiple-file format

```{bash, echo=T, eval=F}
tar -zxvf patient_database.tar.gz
```

## Working with multiple files in directory: `wildcards`

-   `*` is called 'grob' and it matches or completes to *anything*

Matching everything that begins with `4` or `12`:

```{bash, echo=T}
cat ../../data/patient_database/4*
```

```{bash, echo=T}
ls ../../data/patient_database/12*
```

## Grob continued `*`

Matching everything with `healthy` in it

```{bash, echo=T}
ls ../../data/patient_database/*healthy*
```

Matching everything that ends in `.csv`

```{bash, echo=T}
# and truncating a little since there are alot
ls ../../data/patient_database/*.csv | head
```

## Practice 06: Grob

Print all the file names that contain `mut`

### output

```{bash}
ls ../../data/patient_database/*mut*
```

## More limited matching: number of characters `???`

-   `?` is used when the *number unknown of characters* is known

Only double digit patient ID numbers

```{bash, echo=T}
ls ../../data/patient_database/??_*.csv
```

## More limited matching: number of characters `???`

Only single digit patient ID numbers

```{bash, echo=T}
ls ../../data/patient_database/?_*.csv
```

## Practice 07: `?`

Print all file names that contain `mut` without explicitly including `mut` in the command

### output

```{bash}
ls ../../data/patient_database/*_???????_card.csv
```

## More specific matches: ranges `[]`

Ranges of numbers:

```{bash, echo=T}
ls ../../data/patient_database/[2-4]_*.csv
```

List of characters:

```{bash, echo=T}
ls ../../data/patient_database/*_[T,K]*.csv
```

## Practice 08: `[]`

Print all file names that start with digits 1 - 9

### output

```{bash}
ls ../../data/patient_database/[1-9]_*
```

## Back to work...Job #2

Alright, now we have the tools to do a bit more work with files and directories

-   take the files you captured **Practice 08** and combine them into a single `patient_data.csv` with column names.

## Job #2 Output

on my mac (`zsh`), \[1-9\] include 10,11,12, this doesn't seem to generalize

```{bash}
head -1 ../../data/patient_database/10_TP53healthy_card.csv > ../../data/patient_data.csv & cat ../../data/patient_database/[1-9]*_*mut* | grep -v 'patient' >> ../../data/patient_data.csv
cat ../../data/patient_data.csv
```

## Reflection:

-   We can operate on contents `files` : rows, columns

-   We can operate on the contents of `directories` : `files` themselves

    -   this is greatly facilitated by `wildcards`

-   One thing is missing from making this whole approach fast, reproducible, and easy -- what do you think it is?
